---
layout: post
title: P value fallacy and misconceptions
tags:
- statistics
- p value
- American Statistical Association
- misuse

mathjax: true
---

## Definition of p-value
&nbsp;

- P value is frequently used as a metric to evaluate significance of hypothesis testings
- It is the probability of observing the same or greater statistical summary than actual observed results, **given that the null hypothesis is true**
- It is used as a determinator to reject the null hypothesis; the less the p-value, the less the probability of getting the observed results is. This is why null hypothesis is rejected if p-value is low. 

&nbsp;
&nbsp;
<img src="/assets/images/p-val.png">
&nbsp;
&nbsp;

## Misconceptions
&nbsp;

P value is often used as a metric to show how significant the results of experiments are. However, the misunderstandings of p-values are prevalent many scientific research and scientific educations. This made the American Statistical Association release statement on p-values and statistical significance. 

The following is the definition of p-value in the statement of ASA:
>"Informally,  p-value is the probability under a specified statistical model that a statistical summary of the data (e.g., the sample mean difference between two compared groups) would be equal to or more extreme than its observed value."

&nbsp;
These are some common **misconceptions regarding p-values**:

1. P-value is ***not a probability that the null hypothesis is true or the probability that the alternative hypothesis is false***

2. P-value is ***not the probability that the observed effects were produced by random selection***

3. The **0.05** significance level is merely a **convention**

4. P-value **does not indicate the size or importance of the observed effect**

&nbsp;
&nbsp;

### Transposed Conditional Fallacy
&nbsp;
According to the definition, p-value refers to the probability of observing a result given that some hypothesis is true. In a mathematical expression:
<p> $$ P(Observation \vert Hypothesis = True ) $$ </p>
        
&nbsp;
However, p-value is erroneously used as a "score" or "index" to assess the true or false of a hypothesis:
<p> $$ P( Hypothesis = True \vert Observation ) $$ </p>

&nbsp;

Since the two expressions are different, misunderstanding these two conceptions will cause conditional probability fallacy.
&nbsp;
&nbsp;

## Principles to have in mind when using p-values

&nbsp;

Many research use p-value to test the true or false of their model or classify results. However, p-value cannot be a sole evidence that concludes the viability of research or model. It is not a panacea to statistical inference or model development. Here are the principles that ASA strongly advise when using p-values:

&nbsp;

> 1. P-values can indicate how incompatible the data are with a specified statistical model.
> 2. P-values do not measure the probability that the studied hypothesis is true, or the probability that the data were produced by random chance alone
> 3. Scientific conclusions and business or policy decisions should not be based only on whether a p0value passes a specific threshold
> 4. Proper inference requires full reporting and transparency
> 5. A p-value, or statistical significance does not measure the size of an effect or the importance of a result
> 6. By itself, a p-value does not provide a good measure of evidence regarding a model or hypothesis


&nbsp;
&nbsp;

In a gist, p-value 
